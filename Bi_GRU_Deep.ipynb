{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"name":"Bi_GRU_Deep.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"pr3fs8n9QoRN","colab_type":"code","colab":{}},"source":["import keras\n","import re\n","import gc\n","import os\n","import nltk\n","import string\n","import gensim\n","from keras.engine.saving import model_from_json\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.preprocessing import sequence\n","from keras.models import Sequential ,Model\n","from keras.layers import Flatten , BatchNormalization,LSTM, GRU ,Conv1D ,MaxPooling1D,Dense\n","from keras.layers import GlobalMaxPooling1D ,TimeDistributed, Masking\n","from keras.layers import Dropout,Activation\n","from keras.layers.embeddings import Embedding\n","from keras.layers.convolutional import MaxPooling1D,Conv1D\n","from keras.layers.core import Activation, Dropout, Dense, RepeatVector\n","from keras.preprocessing.text import one_hot\n","from keras.wrappers.scikit_learn import KerasRegressor\n","from keras.layers import Embedding,Input,GlobalAveragePooling1D,Bidirectional\n","import matplotlib.pyplot as plt\n","import plotly.offline as py\n","import plotly.graph_objs as go\n","import numpy as np\n","import pandas as pd\n","from numpy import array\n","from textblob import TextBlob\n","from sklearn.manifold import TSNE\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem.porter import PorterStemmer\n","from nltk.stem.snowball import SnowballStemmer\n","from sklearn.model_selection import train_test_split\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.decomposition import PCA, LatentDirichletAllocation\n","from keras.layers import Bidirectional\n","from keras.callbacks import EarlyStopping"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EZ-Dlf4pRjaW","colab_type":"code","outputId":"c39347a3-514c-48ea-ce19-e1602b991fc4","executionInfo":{"status":"ok","timestamp":1577013035838,"user_tz":-120,"elapsed":1789,"user":{"displayName":"Enas Kh","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCy_4FkZMlIejlqYK_ldc6zeb0BADLE1q2gcBvJ=s64","userId":"14585450817422253727"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M4hcbWY0QoRT","colab_type":"code","colab":{}},"source":["# Read the data\n","df_train = pd.read_csv('/content/drive/My Drive/Third Semester/Machine Learning /MLProject/December 22/newtrain.csv')\n","df_dev= pd.read_csv('/content/drive/My Drive/Third Semester/Machine Learning /MLProject/December 22/newdev.csv')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QB62KcEeQoRV","colab_type":"code","outputId":"18db600d-3510-40d5-a141-9bc50e14e1a9","executionInfo":{"status":"ok","timestamp":1577013430286,"user_tz":-120,"elapsed":2303,"user":{"displayName":"Enas Kh","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCy_4FkZMlIejlqYK_ldc6zeb0BADLE1q2gcBvJ=s64","userId":"14585450817422253727"}},"colab":{"base_uri":"https://localhost:8080/","height":374}},"source":["# Dataset is now stored in a Pandas Dataframe\n","df_train.head()\n","print(df_train['train-new'].head(20))"],"execution_count":19,"outputs":[{"output_type":"stream","text":["0       franc hunt citizen join twin without trial iraq\n","1     pentagon claim 2000 increas russian troll bowl...\n","2     iceland pm call snap vote pedophil furor crash...\n","3               appar first iran israel slap militarili\n","4                told week ago flynn misl school presid\n","5               22 sound made speech congress one chart\n","6                  doj alert system flag laughter polic\n","7     someon grew among fundamentalist moron surpris...\n","8               canadian may pay tax american get looni\n","9                   dutch minist resign drug baron blow\n","10    dozen dead possibl ga bloat syria regim deni a...\n","11                                   made pilat le safe\n","12               second nomine class secretari withdraw\n","13                                        gop rememb 80\n","14    mississippi law endors anti lgbt bia attorney ...\n","15                          chibok salami reunit famili\n","16    bill aim marri christian minor group pakistan ...\n","17                           pull rental car junk trunk\n","18    presid forc leav zealand involv seriou crimin ...\n","19    erdogan reject arab demand turkish turkey stay...\n","Name: train-new, dtype: object\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-8uftzAxQoRY","colab_type":"code","colab":{}},"source":["# apply tokenization and create sequence matrix on training dataset to make all text the same length\n","x_train = df_train['train-new']  # to store data as string\n","x_dev = df_dev['dev_new'] # to store dev data as string\n","#max_words = 300  # max number of word for Glove\n","max_words = 3574 # for W2V\n","#max_words = 17000  # max number of word for fasttext\n","max_len = 75  # max number of word in each row\n","def  tokenizersplit(str):\n","    return str.split();"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ocpF1YI0QoRa","colab_type":"code","outputId":"947098a1-bfe6-4851-d642-50b6dbb01e2b","executionInfo":{"status":"ok","timestamp":1577013434467,"user_tz":-120,"elapsed":2109,"user":{"displayName":"Enas Kh","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCy_4FkZMlIejlqYK_ldc6zeb0BADLE1q2gcBvJ=s64","userId":"14585450817422253727"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["tok = Tokenizer(num_words=max_words)\n","tok.fit_on_texts(x_train)  # The Tokenizer stores everything in the \"word_index\" during \"fit_on_texts\".\n","sequences = tok.texts_to_sequences(x_train)  # Then, when calling the \"texts_to_sequences method\", only the top num_words are considered.\n","sequences_matrix = sequence.pad_sequences(sequences, maxlen=max_len, dtype='int32', padding='post', truncating='post', value=0.0)  # Pads sequences to the same length.\n","print(sequences_matrix)\n","print('Pad sequence of dev data.....')"],"execution_count":21,"outputs":[{"output_type":"stream","text":["[[ 406  577 1924 ...    0    0    0]\n"," [ 803   66 3358 ...    0    0    0]\n"," [3359  465   11 ...    0    0    0]\n"," ...\n"," [2244  581 1928 ...    0    0    0]\n"," [  94  577   68 ...    0    0    0]\n"," [ 231   52  371 ...    0    0    0]]\n","Pad sequence of dev data.....\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"M9wJETpfQoRc","colab_type":"code","outputId":"ec6d3bd1-a727-4b8d-c884-a60717cbc4b4","executionInfo":{"status":"ok","timestamp":1577014061241,"user_tz":-120,"elapsed":1399,"user":{"displayName":"Enas Kh","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCy_4FkZMlIejlqYK_ldc6zeb0BADLE1q2gcBvJ=s64","userId":"14585450817422253727"}},"colab":{"base_uri":"https://localhost:8080/","height":136}},"source":["# For dev dataset\n","tok = Tokenizer(num_words=max_words)\n","tok.fit_on_texts(x_dev)  # The Tokenizer stores everything in the \"word_index\" during \"fit_on_texts\".\n","sequences_dev = tok.texts_to_sequences(x_dev)  # Then, when calling the \"texts_to_sequences method\", only the top num_words are considered.\n","sequences_matrix_dev = sequence.pad_sequences(sequences_dev, maxlen=max_len, dtype='int32', padding='post', truncating='post', value=0.0)  # Pads sequences to the same length.\n","print(sequences_matrix_dev)"],"execution_count":22,"outputs":[{"output_type":"stream","text":["[[ 548  414 1218 ...    0    0    0]\n"," [ 103  892  208 ...    0    0    0]\n"," [1223  185  449 ...    0    0    0]\n"," ...\n"," [   3  102  510 ...    0    0    0]\n"," [2243 2244  653 ...    0    0    0]\n"," [ 300 1562    0 ...    0    0    0]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rtJL0iIcQoRe","colab_type":"code","outputId":"673d3248-3c37-445d-e768-85717aba9c2a","executionInfo":{"status":"error","timestamp":1577013685855,"user_tz":-120,"elapsed":1628,"user":{"displayName":"Enas Kh","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mCy_4FkZMlIejlqYK_ldc6zeb0BADLE1q2gcBvJ=s64","userId":"14585450817422253727"}},"colab":{"base_uri":"https://localhost:8080/","height":479}},"source":["#############################################################################################\n","# Read the embedding file as glove type\n","\"\"\"print('loading word embeddings (Glove)...')\n","max_features = 300\n","EMBEDDING_FILE = \"glove.840B.300d.txt\"\n","\n","def get_coefs(word, *arr): return word, np.asarray(arr, dtype='float32')\n","embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE, encoding=\"utf8\"))\n","\n","all_embs = np.stack(embeddings_index.values())\n","emb_mean, emb_std = all_embs.mean(), all_embs.std()\n","embed_size = all_embs.shape[1]\n","\n","word_index = tok.word_index\n","nb_words = min(max_features, len(word_index))\n","embedding_matrix_glove = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n","for word, i in word_index.items():\n","    if i >= max_features: continue\n","    embedding_vector = embeddings_index.get(word)\n","    if embedding_vector is not None: embedding_matrix_glove[i] = embedding_vector\n","\n","del embeddings_index;\n","gc.collect()\"\"\"\n","#end of glove\n","##############################################################################################\n","##############################################################################################\n","# Word2Vec (GoogleNews) word embedding\n","print('loading word embeddings (W2V)...')\n","import gensim.models.keyedvectors as word2vec\n","\n","def loadEmbeddingMatrix(typeToLoad):\n","    # load different embedding file from Kaggle depending on which embedding\n","    # matrix we are going to experiment with\n","    if (typeToLoad == \"word2vec\"):\n","        word2vecDict = word2vec.KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin\", binary=True)\n","        embed_size = 300;\n","        embeddings_index = dict()\n","        for word in word2vecDict.wv.vocab:\n","            embeddings_index[word] = word2vecDict.word_vec(word)\n","        print('Loaded %s word vectors.' % len(embeddings_index))\n","\n","    gc.collect()\n","    # We get the mean and standard deviation of the embedding weights so that we could maintain the\n","    # same statistics for the rest of our own random generated weights.\n","    all_embs = np.stack(list(embeddings_index.values()))\n","    emb_mean, emb_std = all_embs.mean(), all_embs.std()\n","\n","    nb_words = len(tok.word_index)\n","    # We are going to set the embedding size to the pretrained dimension as we are replicating it.\n","    # the size will be Number of Words in Vocab X Embedding Size\n","    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n","    gc.collect()\n","\n","    # With the newly created embedding matrix, we'll fill it up with the words that we have in both\n","    # our own dictionary and loaded pretrained embedding.\n","    embeddedCount = 0\n","    for word, i in tok.word_index.items():\n","        i -= 1\n","        # then we see if this word is in glove's dictionary, if yes, get the corresponding weights\n","        embedding_vector = embeddings_index.get(word)\n","        # and store inside the embedding matrix that we will train later on.\n","        if embedding_vector is not None:\n","            embedding_matrix[i] = embedding_vector\n","            embeddedCount += 1\n","    print('total embedded:', embeddedCount, 'common words')\n","\n","    del (embeddings_index)\n","    gc.collect()\n","    # finally, return the embedding matrix\n","    return embedding_matrix\n","embedding_matrix_w2v = loadEmbeddingMatrix('word2vec')\n","##############################################################################################\n","\"\"\"# Fast text Word Embedding\n","print('loading word embeddings (Fasttext)...')\n","embeddings_dictionary = dict()\n","fastetxt_file = open('wiki-news-300d-1M.vec', encoding=\"utf8\")\n","for line in fastetxt_file:\n","    records = line.split()\n","    word = records[0]\n","    vector_dimensions = np.asarray(records[1:], dtype='float32')\n","    embeddings_dictionary [word] = vector_dimensions\n","\n","fastetxt_file.close()\n","embedding_matrix_fast = np.zeros((max_words, 300))\n","for word, index in tok.word_index.items():\n","    embedding_vector = embeddings_dictionary.get(word)\n","    if embedding_vector is not None:\n","        embedding_matrix_fast[index] = embedding_vector\n","# end of fasttext\n","##############################################################################################\"\"\"\n","\"\"\"#Elmo Word Embedding\n","\n","# end of Elmo\n","##############################################################################################\"\"\""],"execution_count":0,"outputs":[{"output_type":"stream","text":["loading word embeddings (W2V)...\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning:\n","\n","This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n","\n"],"name":"stderr"},{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-c50b13401868>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m# finally, return the embedding matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0membedding_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m \u001b[0membedding_matrix_w2v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadEmbeddingMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'word2vec'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;31m##############################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \"\"\"# Fast text Word Embedding\n","\u001b[0;32m<ipython-input-13-c50b13401868>\u001b[0m in \u001b[0;36mloadEmbeddingMatrix\u001b[0;34m(typeToLoad)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# matrix we are going to experiment with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtypeToLoad\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"word2vec\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m         \u001b[0mword2vecDict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GoogleNews-vectors-negative300.bin\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m         \u001b[0membed_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0membeddings_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m   1436\u001b[0m         return _load_word2vec_format(\n\u001b[1;32m   1437\u001b[0m             \u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfvocab\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode_errors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0municode_errors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1438\u001b[0;31m             limit=limit, datatype=datatype)\n\u001b[0m\u001b[1;32m   1439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_keras_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/utils_any2vec.py\u001b[0m in \u001b[0;36m_load_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loading projection weights from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msmart_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m         \u001b[0mheader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# throws for invalid file format\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36msmart_open\u001b[0;34m(uri, mode, **kw)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m     return open(uri, mode, ignore_ext=ignore_extension,\n\u001b[0;32m--> 458\u001b[0;31m                 transport_params=transport_params, **scrubbed_kwargs)\n\u001b[0m\u001b[1;32m    459\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(uri, mode, buffering, encoding, errors, newline, closefd, opener, ignore_ext, transport_params)\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m         \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m     )\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py\u001b[0m in \u001b[0;36m_shortcut_open\u001b[0;34m(uri, mode, ignore_ext, buffering, encoding, errors)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPY3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mopen_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopen_kwargs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_builtin_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_uri\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muri_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbuffering\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'GoogleNews-vectors-negative300.bin'"]}]},{"cell_type":"code","metadata":{"id":"ADLFtqwZQoRg","colab_type":"code","colab":{}},"source":["data_label = df_train['meanGrade']\n","embedding_size = 300\n","model = Sequential()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Oq7kWswaQoRh","colab_type":"code","colab":{}},"source":["# Embedding layer\n","model.add(\n","    Embedding(input_dim=max_words,\n","              input_length = max_len,\n","              output_dim=embedding_size,\n","              weights=[embedding_matrix_w2v],\n","              trainable=False,\n","              mask_zero=True))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"x1Sp2VkzQoRj","colab_type":"code","outputId":"b9d25f68-a930-4955-dd83-4a2b21f25940","colab":{}},"source":["# Masking layer for pre-trained embeddings\n","model.add(Masking(mask_value=0.0))\n","\n","#input layer\n","#Recurrent layer\n","#model.add(GRU(64, return_sequences=False, dropout=0.1, recurrent_dropout=0.1, activation='linear'))#GRU\n","model.add(Bidirectional(GRU(64, kernel_initializer='normal', input_dim = x_train.shape[0], activation='sigmoid')))\n","#hidden layer\n","# Fully connected layer\n","model.add(Dense(25, kernel_initializer='normal',activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(BatchNormalization())\n","\n","model.add(Dense(15, kernel_initializer='normal',activation='relu'))\n","model.add(Dropout(0.5))\n","model.add(BatchNormalization())\n","\n","#model.add(Dense(25, kernel_initializer='normal',activation='relu'))\n","#model.add(Dropout(0.5))\n","#model.add(BatchNormalization())\n","\n","\n","# Output layer\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# Compile the model\n","model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n","model.summary()\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["C:\\Users\\AMCT\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning:\n","\n","The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n","\n","C:\\Users\\AMCT\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: UserWarning:\n","\n","Update your `GRU` call to the Keras 2 API: `GRU(64, kernel_initializer=\"normal\", activation=\"sigmoid\", input_shape=(None, 965...)`\n","\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_2 (Embedding)      (None, 75, 300)           1072200   \n","_________________________________________________________________\n","masking_1 (Masking)          (None, 75, 300)           0         \n","_________________________________________________________________\n","bidirectional_1 (Bidirection (None, 128)               140160    \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 25)                3225      \n","_________________________________________________________________\n","dropout_1 (Dropout)          (None, 25)                0         \n","_________________________________________________________________\n","batch_normalization_1 (Batch (None, 25)                100       \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 15)                390       \n","_________________________________________________________________\n","dropout_2 (Dropout)          (None, 15)                0         \n","_________________________________________________________________\n","batch_normalization_2 (Batch (None, 15)                60        \n","_________________________________________________________________\n","dense_3 (Dense)              (None, 1)                 16        \n","=================================================================\n","Total params: 1,216,151\n","Trainable params: 143,871\n","Non-trainable params: 1,072,280\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SPIDJyBdQoRk","colab_type":"code","outputId":"647a9967-f593-412e-8945-80d7f543f836","colab":{}},"source":["print('Train...')\n","# Fit the model\n","earlystop = EarlyStopping(monitor='mean_squared_error', mode='auto', patience=10, verbose=1)\n","history = model.fit(sequences_matrix, data_label, batch_size=180000, epochs=300,verbose=1, callbacks=[earlystop])\n","\n","#history = model.fit(X_train, y_train, epochs=300, batch_size=180000, validation_data=(X_valid, y_valid), callbacks=[earlystop])\n","\n","#Test the model\n","# serialize model to JSON\n","#model_json = model.to_json()\n","#with open(\"model.json\", \"w\") as json_file:\n","    #json_file.write(model_json)\n","# serialize weights to HDF5\n","#model.save_weights(\"model.h5\")\n","#print(\"Saved model to disk\")\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Train...\n","WARNING:tensorflow:From C:\\Users\\AMCT\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.cast instead.\n","Epoch 1/300\n","9652/9652 [==============================] - 25s 3ms/step - loss: 0.6017 - mean_squared_error: 0.6017\n","Epoch 2/300\n","9652/9652 [==============================] - 27s 3ms/step - loss: 0.5921 - mean_squared_error: 0.5921\n","Epoch 3/300\n","9652/9652 [==============================] - 25s 3ms/step - loss: 0.5951 - mean_squared_error: 0.5951\n","Epoch 4/300\n","9652/9652 [==============================] - 24s 2ms/step - loss: 0.5872 - mean_squared_error: 0.5872\n","Epoch 5/300\n","9652/9652 [==============================] - 24s 2ms/step - loss: 0.5810 - mean_squared_error: 0.5810\n","Epoch 6/300\n","9652/9652 [==============================] - 22s 2ms/step - loss: 0.5818 - mean_squared_error: 0.5818\n","Epoch 7/300\n","9652/9652 [==============================] - 28s 3ms/step - loss: 0.5900 - mean_squared_error: 0.5900\n","Epoch 8/300\n","9652/9652 [==============================] - 28s 3ms/step - loss: 0.5772 - mean_squared_error: 0.5772\n","Epoch 9/300\n","9652/9652 [==============================] - 29s 3ms/step - loss: 0.5777 - mean_squared_error: 0.5777\n","Epoch 10/300\n","9652/9652 [==============================] - 36s 4ms/step - loss: 0.5745 - mean_squared_error: 0.5745\n","Epoch 11/300\n","9652/9652 [==============================] - 27s 3ms/step - loss: 0.5757 - mean_squared_error: 0.5757\n","Epoch 12/300\n","9652/9652 [==============================] - 26s 3ms/step - loss: 0.5656 - mean_squared_error: 0.5656\n","Epoch 13/300\n","9652/9652 [==============================] - 27s 3ms/step - loss: 0.5667 - mean_squared_error: 0.5667\n","Epoch 14/300\n","9652/9652 [==============================] - 24s 3ms/step - loss: 0.5631 - mean_squared_error: 0.5631\n","Epoch 15/300\n","9652/9652 [==============================] - 22s 2ms/step - loss: 0.5607 - mean_squared_error: 0.5607\n","Epoch 16/300\n","9652/9652 [==============================] - 22s 2ms/step - loss: 0.5553 - mean_squared_error: 0.5553\n","Epoch 17/300\n","9652/9652 [==============================] - 23s 2ms/step - loss: 0.5569 - mean_squared_error: 0.5569\n","Epoch 18/300\n","9652/9652 [==============================] - 23s 2ms/step - loss: 0.5478 - mean_squared_error: 0.5478\n","Epoch 19/300\n","9652/9652 [==============================] - 23s 2ms/step - loss: 0.5531 - mean_squared_error: 0.5531\n","Epoch 20/300\n","9652/9652 [==============================] - 22s 2ms/step - loss: 0.5459 - mean_squared_error: 0.5459\n","Epoch 21/300\n","9652/9652 [==============================] - 22s 2ms/step - loss: 0.5480 - mean_squared_error: 0.5480\n","Epoch 22/300\n","9652/9652 [==============================] - 22s 2ms/step - loss: 0.5456 - mean_squared_error: 0.5456\n","Epoch 23/300\n","9652/9652 [==============================] - 27s 3ms/step - loss: 0.5435 - mean_squared_error: 0.5435\n","Epoch 24/300\n","9652/9652 [==============================] - 23s 2ms/step - loss: 0.5435 - mean_squared_error: 0.5435\n","Epoch 25/300\n","9652/9652 [==============================] - 22s 2ms/step - loss: 0.5409 - mean_squared_error: 0.5409\n","Epoch 26/300\n","9652/9652 [==============================] - 22s 2ms/step - loss: 0.5334 - mean_squared_error: 0.5334\n","Epoch 27/300\n","9652/9652 [==============================] - 23s 2ms/step - loss: 0.5368 - mean_squared_error: 0.5368\n","Epoch 28/300\n","9652/9652 [==============================] - 22s 2ms/step - loss: 0.5287 - mean_squared_error: 0.5287\n","Epoch 29/300\n","9652/9652 [==============================] - 22s 2ms/step - loss: 0.5233 - mean_squared_error: 0.5233\n","Epoch 30/300\n","9652/9652 [==============================] - 22s 2ms/step - loss: 0.5274 - mean_squared_error: 0.5274\n","Epoch 31/300\n","9652/9652 [==============================] - 28s 3ms/step - loss: 0.5250 - mean_squared_error: 0.5250\n","Epoch 32/300\n","9652/9652 [==============================] - 31s 3ms/step - loss: 0.5202 - mean_squared_error: 0.5202\n","Epoch 33/300\n","9652/9652 [==============================] - 31s 3ms/step - loss: 0.5213 - mean_squared_error: 0.5213\n","Epoch 34/300\n","9652/9652 [==============================] - 28s 3ms/step - loss: 0.5136 - mean_squared_error: 0.5136\n","Epoch 35/300\n","9652/9652 [==============================] - 31s 3ms/step - loss: 0.5092 - mean_squared_error: 0.5092\n","Epoch 36/300\n","9652/9652 [==============================] - 26s 3ms/step - loss: 0.5060 - mean_squared_error: 0.5060\n","Epoch 37/300\n","9652/9652 [==============================] - 24s 3ms/step - loss: 0.5030 - mean_squared_error: 0.5030\n","Epoch 38/300\n","9652/9652 [==============================] - 29s 3ms/step - loss: 0.5027 - mean_squared_error: 0.5027\n","Epoch 39/300\n","9652/9652 [==============================] - 25s 3ms/step - loss: 0.5040 - mean_squared_error: 0.5040\n","Epoch 40/300\n","9652/9652 [==============================] - 27s 3ms/step - loss: 0.4971 - mean_squared_error: 0.4971\n","Epoch 41/300\n","9652/9652 [==============================] - 28s 3ms/step - loss: 0.4952 - mean_squared_error: 0.4952\n","Epoch 42/300\n","9652/9652 [==============================] - 24s 3ms/step - loss: 0.4949 - mean_squared_error: 0.4949\n","Epoch 43/300\n","9652/9652 [==============================] - 27s 3ms/step - loss: 0.4920 - mean_squared_error: 0.4920\n","Epoch 44/300\n","9652/9652 [==============================] - 28s 3ms/step - loss: 0.4866 - mean_squared_error: 0.4866\n","Epoch 45/300\n","9652/9652 [==============================] - 25s 3ms/step - loss: 0.4864 - mean_squared_error: 0.4864\n","Epoch 46/300\n","9652/9652 [==============================] - 25s 3ms/step - loss: 0.4872 - mean_squared_error: 0.4872\n","Epoch 47/300\n","9652/9652 [==============================] - 26s 3ms/step - loss: 0.4813 - mean_squared_error: 0.4813\n","Epoch 48/300\n","9652/9652 [==============================] - 29s 3ms/step - loss: 0.4760 - mean_squared_error: 0.4760\n","Epoch 49/300\n","9652/9652 [==============================] - 26s 3ms/step - loss: 0.4727 - mean_squared_error: 0.4727\n","Epoch 50/300\n","9652/9652 [==============================] - 28s 3ms/step - loss: 0.4689 - mean_squared_error: 0.4689\n","Epoch 51/300\n","9652/9652 [==============================] - 27s 3ms/step - loss: 0.4680 - mean_squared_error: 0.4680\n","Epoch 52/300\n","9652/9652 [==============================] - 34s 3ms/step - loss: 0.4620 - mean_squared_error: 0.4620\n","Epoch 53/300\n","9652/9652 [==============================] - 30s 3ms/step - loss: 0.4600 - mean_squared_error: 0.4600\n","Epoch 54/300\n","9652/9652 [==============================] - 24s 3ms/step - loss: 0.4576 - mean_squared_error: 0.4576\n","Epoch 55/300\n","9652/9652 [==============================] - 24s 2ms/step - loss: 0.4544 - mean_squared_error: 0.4544\n","Epoch 56/300\n","9652/9652 [==============================] - 29s 3ms/step - loss: 0.4522 - mean_squared_error: 0.4522\n","Epoch 57/300\n","9652/9652 [==============================] - 27s 3ms/step - loss: 0.4499 - mean_squared_error: 0.4499\n","Epoch 58/300\n","9652/9652 [==============================] - 24s 2ms/step - loss: 0.4514 - mean_squared_error: 0.4514\n","Epoch 59/300\n","9652/9652 [==============================] - 24s 3ms/step - loss: 0.4473 - mean_squared_error: 0.4473\n","Epoch 60/300\n","9652/9652 [==============================] - 25s 3ms/step - loss: 0.4459 - mean_squared_error: 0.4459\n","Epoch 61/300\n","9652/9652 [==============================] - 23s 2ms/step - loss: 0.4438 - mean_squared_error: 0.4438\n","Epoch 62/300\n","9652/9652 [==============================] - 25s 3ms/step - loss: 0.4418 - mean_squared_error: 0.4418\n","Epoch 63/300\n","9652/9652 [==============================] - 24s 2ms/step - loss: 0.4400 - mean_squared_error: 0.4400\n","Epoch 64/300\n","9652/9652 [==============================] - 28s 3ms/step - loss: 0.4375 - mean_squared_error: 0.4375\n","Epoch 65/300\n","9652/9652 [==============================] - 32s 3ms/step - loss: 0.4349 - mean_squared_error: 0.4349\n","Epoch 66/300\n","9652/9652 [==============================] - 23s 2ms/step - loss: 0.4348 - mean_squared_error: 0.4348\n","Epoch 67/300\n","9652/9652 [==============================] - 29s 3ms/step - loss: 0.4322 - mean_squared_error: 0.4322\n","Epoch 68/300\n","9652/9652 [==============================] - 25s 3ms/step - loss: 0.4318 - mean_squared_error: 0.4318\n","Epoch 69/300\n","9652/9652 [==============================] - 27s 3ms/step - loss: 0.4295 - mean_squared_error: 0.4295\n","Epoch 70/300\n"],"name":"stdout"},{"output_type":"stream","text":["9652/9652 [==============================] - 25s 3ms/step - loss: 0.4260 - mean_squared_error: 0.4260\n","Epoch 71/300\n","9652/9652 [==============================] - 24s 3ms/step - loss: 0.4248 - mean_squared_error: 0.4248\n","Epoch 72/300\n","9652/9652 [==============================] - 24s 2ms/step - loss: 0.4234 - mean_squared_error: 0.4234\n","Epoch 73/300\n","9652/9652 [==============================] - 25s 3ms/step - loss: 0.4237 - mean_squared_error: 0.4237\n","Epoch 74/300\n","9652/9652 [==============================] - 24s 2ms/step - loss: 0.4225 - mean_squared_error: 0.4225\n","Epoch 75/300\n","9652/9652 [==============================] - 23s 2ms/step - loss: 0.4208 - mean_squared_error: 0.4208\n","Epoch 76/300\n","9652/9652 [==============================] - 24s 3ms/step - loss: 0.4195 - mean_squared_error: 0.4195\n","Epoch 77/300\n","9652/9652 [==============================] - 23s 2ms/step - loss: 0.4180 - mean_squared_error: 0.4180\n","Epoch 78/300\n","9652/9652 [==============================] - 28s 3ms/step - loss: 0.4180 - mean_squared_error: 0.4180\n","Epoch 79/300\n","9652/9652 [==============================] - 29s 3ms/step - loss: 0.4139 - mean_squared_error: 0.4139\n","Epoch 80/300\n","9652/9652 [==============================] - 25s 3ms/step - loss: 0.4164 - mean_squared_error: 0.4164\n","Epoch 81/300\n","9652/9652 [==============================] - 28s 3ms/step - loss: 0.4129 - mean_squared_error: 0.4129\n","Epoch 82/300\n","9652/9652 [==============================] - 28s 3ms/step - loss: 0.4128 - mean_squared_error: 0.4128\n","Epoch 83/300\n","9652/9652 [==============================] - 25s 3ms/step - loss: 0.4107 - mean_squared_error: 0.4107\n","Epoch 84/300\n","9652/9652 [==============================] - 24s 3ms/step - loss: 0.4113 - mean_squared_error: 0.4113\n","Epoch 85/300\n","9652/9652 [==============================] - 26s 3ms/step - loss: 0.4096 - mean_squared_error: 0.4096\n","Epoch 86/300\n","9652/9652 [==============================] - 23s 2ms/step - loss: 0.4072 - mean_squared_error: 0.4072\n","Epoch 87/300\n","9652/9652 [==============================] - 29s 3ms/step - loss: 0.4069 - mean_squared_error: 0.4069\n","Epoch 88/300\n","9652/9652 [==============================] - 29s 3ms/step - loss: 0.4064 - mean_squared_error: 0.4064\n","Epoch 89/300\n","9652/9652 [==============================] - 23s 2ms/step - loss: 0.4025 - mean_squared_error: 0.4025\n","Epoch 90/300\n","9652/9652 [==============================] - 26s 3ms/step - loss: 0.4055 - mean_squared_error: 0.4055\n","Epoch 91/300\n","9652/9652 [==============================] - 25s 3ms/step - loss: 0.4038 - mean_squared_error: 0.4038\n","Epoch 92/300\n","9652/9652 [==============================] - 28s 3ms/step - loss: 0.4008 - mean_squared_error: 0.4008\n","Epoch 93/300\n","9652/9652 [==============================] - 24s 3ms/step - loss: 0.4010 - mean_squared_error: 0.4010\n","Epoch 94/300\n","9652/9652 [==============================] - 27s 3ms/step - loss: 0.4009 - mean_squared_error: 0.4009\n","Epoch 95/300\n","9652/9652 [==============================] - 26s 3ms/step - loss: 0.3999 - mean_squared_error: 0.3999\n","Epoch 96/300\n","9652/9652 [==============================] - 31s 3ms/step - loss: 0.4007 - mean_squared_error: 0.4007\n","Epoch 97/300\n","9652/9652 [==============================] - 23s 2ms/step - loss: 0.3992 - mean_squared_error: 0.3992\n","Epoch 98/300\n","9652/9652 [==============================] - 28s 3ms/step - loss: 0.3960 - mean_squared_error: 0.3960\n","Epoch 99/300\n","9652/9652 [==============================] - 24s 3ms/step - loss: 0.3959 - mean_squared_error: 0.3959\n","Epoch 100/300\n","9652/9652 [==============================] - 30s 3ms/step - loss: 0.3956 - mean_squared_error: 0.3956\n","Epoch 101/300\n","9652/9652 [==============================] - 28s 3ms/step - loss: 0.3938 - mean_squared_error: 0.3938\n","Epoch 102/300\n","9652/9652 [==============================] - 26s 3ms/step - loss: 0.3942 - mean_squared_error: 0.3942\n","Epoch 103/300\n","9652/9652 [==============================] - 23s 2ms/step - loss: 0.3930 - mean_squared_error: 0.3930\n","Epoch 104/300\n","9652/9652 [==============================] - 28s 3ms/step - loss: 0.3923 - mean_squared_error: 0.3923\n","Epoch 105/300\n","9652/9652 [==============================] - 29s 3ms/step - loss: 0.3914 - mean_squared_error: 0.3914\n","Epoch 106/300\n","9652/9652 [==============================] - 23s 2ms/step - loss: 0.3902 - mean_squared_error: 0.3902\n","Epoch 107/300\n","9652/9652 [==============================] - 29s 3ms/step - loss: 0.3890 - mean_squared_error: 0.3890\n","Epoch 108/300\n","9652/9652 [==============================] - 26s 3ms/step - loss: 0.3891 - mean_squared_error: 0.3891\n","Epoch 109/300\n","9652/9652 [==============================] - 24s 2ms/step - loss: 0.3893 - mean_squared_error: 0.3893\n","Epoch 110/300\n","9652/9652 [==============================] - 27s 3ms/step - loss: 0.3874 - mean_squared_error: 0.3874\n","Epoch 111/300\n","9652/9652 [==============================] - 24s 2ms/step - loss: 0.3873 - mean_squared_error: 0.3873\n","Epoch 112/300\n","9652/9652 [==============================] - 29s 3ms/step - loss: 0.3862 - mean_squared_error: 0.3862\n","Epoch 113/300\n","9652/9652 [==============================] - 28s 3ms/step - loss: 0.3834 - mean_squared_error: 0.3834\n","Epoch 114/300\n","9652/9652 [==============================] - 25s 3ms/step - loss: 0.3839 - mean_squared_error: 0.3839\n","Epoch 115/300\n","9652/9652 [==============================] - 28s 3ms/step - loss: 0.3826 - mean_squared_error: 0.3826\n","Epoch 116/300\n","9652/9652 [==============================] - 29s 3ms/step - loss: 0.3836 - mean_squared_error: 0.3836\n","Epoch 117/300\n","9652/9652 [==============================] - 24s 3ms/step - loss: 0.3843 - mean_squared_error: 0.3843\n","Epoch 118/300\n","9652/9652 [==============================] - 29s 3ms/step - loss: 0.3824 - mean_squared_error: 0.3824\n","Epoch 119/300\n","9652/9652 [==============================] - 27s 3ms/step - loss: 0.3822 - mean_squared_error: 0.3822\n","Epoch 120/300\n","9652/9652 [==============================] - 25s 3ms/step - loss: 0.3815 - mean_squared_error: 0.3815\n","Epoch 121/300\n","9652/9652 [==============================] - 23s 2ms/step - loss: 0.3814 - mean_squared_error: 0.3814\n","Epoch 122/300\n","9652/9652 [==============================] - 29s 3ms/step - loss: 0.3802 - mean_squared_error: 0.3802\n","Epoch 123/300\n","9652/9652 [==============================] - 24s 2ms/step - loss: 0.3797 - mean_squared_error: 0.3797\n","Epoch 124/300\n","9652/9652 [==============================] - 29s 3ms/step - loss: 0.3790 - mean_squared_error: 0.3790\n","Epoch 125/300\n","9652/9652 [==============================] - 28s 3ms/step - loss: 0.3784 - mean_squared_error: 0.3784\n","Epoch 126/300\n","9652/9652 [==============================] - 25s 3ms/step - loss: 0.3774 - mean_squared_error: 0.3774\n","Epoch 127/300\n","9652/9652 [==============================] - 28s 3ms/step - loss: 0.3790 - mean_squared_error: 0.3790\n","Epoch 128/300\n","9652/9652 [==============================] - 28s 3ms/step - loss: 0.3774 - mean_squared_error: 0.3774\n","Epoch 129/300\n","9652/9652 [==============================] - 24s 3ms/step - loss: 0.3752 - mean_squared_error: 0.3752\n","Epoch 130/300\n","9652/9652 [==============================] - 24s 3ms/step - loss: 0.3755 - mean_squared_error: 0.3755\n","Epoch 131/300\n","9652/9652 [==============================] - 26s 3ms/step - loss: 0.3763 - mean_squared_error: 0.3763\n","Epoch 132/300\n","9652/9652 [==============================] - 24s 2ms/step - loss: 0.3726 - mean_squared_error: 0.3726\n","Epoch 133/300\n","9652/9652 [==============================] - 31s 3ms/step - loss: 0.3748 - mean_squared_error: 0.3748\n","Epoch 134/300\n","9652/9652 [==============================] - 25s 3ms/step - loss: 0.3723 - mean_squared_error: 0.3723\n","Epoch 135/300\n","9652/9652 [==============================] - 28s 3ms/step - loss: 0.3708 - mean_squared_error: 0.3708\n","Epoch 136/300\n","9652/9652 [==============================] - 30s 3ms/step - loss: 0.3717 - mean_squared_error: 0.3717\n","Epoch 137/300\n","9652/9652 [==============================] - 22s 2ms/step - loss: 0.3709 - mean_squared_error: 0.3709\n","Epoch 138/300\n","9652/9652 [==============================] - 22s 2ms/step - loss: 0.3718 - mean_squared_error: 0.3718\n","Epoch 139/300\n","9652/9652 [==============================] - 22s 2ms/step - loss: 0.3705 - mean_squared_error: 0.3705\n","Epoch 140/300\n","9652/9652 [==============================] - 22s 2ms/step - loss: 0.3716 - mean_squared_error: 0.3716\n"],"name":"stdout"},{"output_type":"stream","text":["Epoch 141/300\n","9652/9652 [==============================] - 21s 2ms/step - loss: 0.3700 - mean_squared_error: 0.3700\n","Epoch 142/300\n","9652/9652 [==============================] - 22s 2ms/step - loss: 0.3713 - mean_squared_error: 0.3713\n","Epoch 143/300\n","9652/9652 [==============================] - 22s 2ms/step - loss: 0.3705 - mean_squared_error: 0.3705\n","Epoch 144/300\n","9652/9652 [==============================] - 21s 2ms/step - loss: 0.3705 - mean_squared_error: 0.3705\n","Epoch 145/300\n","9652/9652 [==============================] - 22s 2ms/step - loss: 0.3685 - mean_squared_error: 0.3685\n","Epoch 146/300\n","9652/9652 [==============================] - 22s 2ms/step - loss: 0.3700 - mean_squared_error: 0.3700\n","Epoch 147/300\n","9652/9652 [==============================] - 22s 2ms/step - loss: 0.3698 - mean_squared_error: 0.3698\n","Epoch 148/300\n","9652/9652 [==============================] - 22s 2ms/step - loss: 0.3675 - mean_squared_error: 0.3675\n","Epoch 149/300\n","9652/9652 [==============================] - 21s 2ms/step - loss: 0.3691 - mean_squared_error: 0.3691\n","Epoch 150/300\n","9652/9652 [==============================] - 21s 2ms/step - loss: 0.3680 - mean_squared_error: 0.3680\n","Epoch 151/300\n","9652/9652 [==============================] - 22s 2ms/step - loss: 0.3664 - mean_squared_error: 0.3664\n","Epoch 152/300\n","9652/9652 [==============================] - 22s 2ms/step - loss: 0.3692 - mean_squared_error: 0.3692\n","Epoch 153/300\n","9652/9652 [==============================] - 22s 2ms/step - loss: 0.3668 - mean_squared_error: 0.3668\n","Epoch 154/300\n","9652/9652 [==============================] - 22s 2ms/step - loss: 0.3660 - mean_squared_error: 0.3660\n","Epoch 155/300\n","9652/9652 [==============================] - 21s 2ms/step - loss: 0.3679 - mean_squared_error: 0.3679\n","Epoch 156/300\n","9652/9652 [==============================] - 22s 2ms/step - loss: 0.3647 - mean_squared_error: 0.3647\n","Epoch 157/300\n","9652/9652 [==============================] - 22s 2ms/step - loss: 0.3637 - mean_squared_error: 0.3637\n","Epoch 158/300\n","9652/9652 [==============================] - 21s 2ms/step - loss: 0.3644 - mean_squared_error: 0.3644\n","Epoch 159/300\n","9652/9652 [==============================] - 22s 2ms/step - loss: 0.3629 - mean_squared_error: 0.3629\n","Epoch 160/300\n","9652/9652 [==============================] - 22s 2ms/step - loss: 0.3628 - mean_squared_error: 0.3628\n","Epoch 161/300\n","9652/9652 [==============================] - 21s 2ms/step - loss: 0.3650 - mean_squared_error: 0.3650\n","Epoch 162/300\n","9652/9652 [==============================] - 22s 2ms/step - loss: 0.3624 - mean_squared_error: 0.3624\n","Epoch 163/300\n","9652/9652 [==============================] - 22s 2ms/step - loss: 0.3630 - mean_squared_error: 0.3630\n","Epoch 164/300\n","9652/9652 [==============================] - 22s 2ms/step - loss: 0.3641 - mean_squared_error: 0.3641\n","Epoch 165/300\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0AdIscn7QoRm","colab_type":"code","outputId":"15ee778d-fe0e-45e5-ba83-f44d994de4b1","colab":{}},"source":["# later...\n","# load json and create model\n","json_file = open('model.json', 'r')\n","loaded_model_json = json_file.read()\n","json_file.close()\n","loaded_model = model_from_json(loaded_model_json)\n","# load weights into new model\n","loaded_model.load_weights(\"model.h5\")\n","\n","print(\"Loaded model from disk\")"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Loaded model from disk\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lS2egNrwQoRo","colab_type":"code","outputId":"04bf1e69-8590-4e3f-9425-e9136511ba5f","colab":{}},"source":["# evaluate loaded model on test data\n","loaded_model.compile(loss='mean_squared_error', optimizer='adam', metrics=['mean_squared_error'])\n","score = loaded_model.predict(sequences_matrix_dev)\n","df_dev['pred']= score\n","header_pre1 = [\"id\", \"pred\"]\n","df_dev.to_csv(r'task-1-output.csv',columns=header_pre1)\n","print(score)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[[0.2678182 ]\n"," [0.40861812]\n"," [0.672675  ]\n"," ...\n"," [0.9452318 ]\n"," [0.4519152 ]\n"," [0.9141047 ]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_ZFLVWanQoRq","colab_type":"code","outputId":"80148cfc-c388-43d8-852c-8c704ff1ea8a","colab":{}},"source":["from matplotlib import pyplot\n","pyplot.subplot(212)\n","pyplot.title('Mean Squared Error')\n","pyplot.plot(history.history['mean_squared_error'], label='train')\n","pyplot.plot(history.history['mean_squared_error'], label='dev')\n","pyplot.legend()\n","pyplot.show()\n"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"BACXVCylQoRr","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}